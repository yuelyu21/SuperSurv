<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>4. High-Dimensional Data &amp; Variable Screening • SuperSurv</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="4. High-Dimensional Data &amp; Variable Screening">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">SuperSurv</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/supersurv-ensemble.html">Get Started</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-tutorials" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Tutorials</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-tutorials">
<li><a class="dropdown-item" href="../articles/supersurv-ensemble.html">1. The SuperSurv Ensemble</a></li>
    <li><a class="dropdown-item" href="../articles/model-performance.html">2. Model Performance</a></li>
    <li><a class="dropdown-item" href="../articles/supersurv-best.html">3. Selection vs. Ensemble</a></li>
    <li><a class="dropdown-item" href="../articles/screening-methods.html">4. Screening Methods</a></li>
    <li><a class="dropdown-item" href="../articles/base-learner-rfsrc.html">5. Random Forests (rfsrc)</a></li>
    <li><a class="dropdown-item" href="../articles/parametric-models.html">6. Parametric Models</a></li>
    <li><a class="dropdown-item" href="../articles/shap-explanations.html">7. SHAP Interpretability</a></li>
    <li><a class="dropdown-item" href="../articles/scaleup-parallel.html">8. Parallel Processing</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/yuelyu21/SuperSurv" aria-label="GitHub"><span class="fa fa-github"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>4. High-Dimensional Data &amp; Variable Screening</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/yuelyu21/SuperSurv/blob/master/vignettes/screening-methods.Rmd" class="external-link"><code>vignettes/screening-methods.Rmd</code></a></small>
      <div class="d-none name"><code>screening-methods.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>In modern clinical research and bioinformatics, it is common to
encounter high-dimensional datasets where the number of predictors
(genes, biomarkers, clinical features) far exceeds the number of
observed events
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>≫</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">p \gg n</annotation></semantics></math>).</p>
<p>Feeding thousands of raw variables directly into complex machine
learning algorithms introduces two massive problems: 1.
<strong>Computational Bottlenecks:</strong> Algorithms like Random
Survival Forests become prohibitively slow. 2.
<strong>Overfitting:</strong> Models will mathematically memorize
background noise instead of true biological signals, destroying
out-of-sample prediction accuracy.</p>
<p><code>SuperSurv</code> elegantly handles this through
<strong>Variable Screening</strong>. Screening acts as a computational
filter <em>before</em> the models are fitted. It evaluates all
predictors, drops the statistical noise, and only passes the most highly
associated features into your base learners.</p>
</div>
<div class="section level2">
<h2 id="simulating-high-dimensional-data">1. Simulating High-Dimensional Data<a class="anchor" aria-label="anchor" href="#simulating-high-dimensional-data"></a>
</h2>
<p>To demonstrate how screening works, we will use our standard
<code>metabric</code> dataset, but we will artificially inject 100
columns of pure random noise. This simulates a high-dimensional genomic
dataset where most measured features have absolutely no relationship to
patient survival.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/yuelyu21/SuperSurv" class="external-link">SuperSurv</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival" class="external-link">survival</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"metabric"</span>, package <span class="op">=</span> <span class="st">"SuperSurv"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create 100 columns of random noise (simulating irrelevant genes/biomarkers)</span></span>
<span><span class="va">n_patients</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">metabric</span><span class="op">)</span></span>
<span><span class="va">noise_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n_patients</span> <span class="op">*</span> <span class="fl">20</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">n_patients</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">noise_data</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"noise_"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span></span>
<span><span class="co"># Combine the real data with the noise</span></span>
<span><span class="va">high_dim_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">metabric</span>, <span class="va">noise_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Standard Train/Test Split</span></span>
<span><span class="va">train_idx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">high_dim_data</span><span class="op">)</span>, <span class="fl">0.7</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">high_dim_data</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">high_dim_data</span><span class="op">[</span><span class="va">train_idx</span>, <span class="op">]</span></span>
<span><span class="va">test</span>  <span class="op">&lt;-</span> <span class="va">high_dim_data</span><span class="op">[</span><span class="op">-</span><span class="va">train_idx</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">X_tr</span> <span class="op">&lt;-</span> <span class="va">train</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">grep</a></span><span class="op">(</span><span class="st">"^x|^noise"</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">high_dim_data</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">X_te</span> <span class="op">&lt;-</span> <span class="va">test</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">grep</a></span><span class="op">(</span><span class="st">"^x|^noise"</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">high_dim_data</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">new.times</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">200</span>, by <span class="op">=</span> <span class="fl">25</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="defining-the-screening-algorithms">2. Defining the Screening Algorithms<a class="anchor" aria-label="anchor" href="#defining-the-screening-algorithms"></a>
</h2>
<p>Just as we have a library for prediction algorithms,
<code>SuperSurv</code> utilizes a library for screening algorithms. You
can pair any prediction model with any screening function to create a
streamlined pipeline.</p>
<p><code>SuperSurv</code> includes a comprehensive suite of built-in
screeners: * <strong><code>screen.marg</code></strong>: Marginal
screening (keeps variables with strong univariate associations). *
<strong><code>screen.glmnet</code></strong>: Penalized Lasso screening
(shrinks irrelevant feature coefficients to exact zero). *
<strong><code>screen.elasticnet</code></strong>: Elastic Net screening
(combines Lasso and Ridge penalties; highly recommended for highly
correlated biological features like gene expression data). *
<strong><code>screen.rfsrc</code></strong>: Tree-based screening (keeps
features with high Random Forest variable importance). *
<strong><code>screen.var</code></strong>: Unsupervised screening (drops
features with near-zero variance). *
<strong><code>screen.all</code></strong>: A baseline passthrough (keeps
all variables without screening).</p>
<p>Let’s build a library that tests different combinations of prediction
and screening:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># We pass a list of vectors. The first element is the prediction model, </span></span>
<span><span class="co"># and the second element is the screening algorithm.</span></span>
<span></span>
<span><span class="va">my_screen_library</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"surv.coxph"</span>, <span class="st">"screen.all"</span><span class="op">)</span>,         <span class="co"># Baseline: Cox model with ALL variables</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"surv.coxph"</span>, <span class="st">"screen.marg"</span><span class="op">)</span>,        <span class="co"># Screen by marginal association, then fit Cox</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"surv.weibull"</span>, <span class="st">"screen.elasticnet"</span><span class="op">)</span>,<span class="co"># Screen via Elastic Net, then fit Weibull</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"surv.rpart"</span>, <span class="st">"screen.var"</span><span class="op">)</span>          <span class="co"># Drop zero-variance noise, then fit a Tree</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># For the censoring library, we use an unscreened approach </span></span>
<span><span class="va">cens_library</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"surv.coxph"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="training-with-embedded-screening">3. Training with Embedded Screening<a class="anchor" aria-label="anchor" href="#training-with-embedded-screening"></a>
</h2>
<p>When we pass this paired library into <code>SuperSurv</code>, the
meta-learner handles the cross-validation with absolute statistical
rigor.</p>
<p><strong>Crucial Methodological Detail:</strong> The screening step is
performed <em>inside</em> the cross-validation folds. If you screen the
entire dataset before splitting it into folds, you cause “data leakage,”
leading to overly optimistic benchmark metrics. <code>SuperSurv</code>
protects you from this automatically.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_highdim</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/SuperSurv.html">SuperSurv</a></span><span class="op">(</span></span>
<span>  time <span class="op">=</span> <span class="va">train</span><span class="op">$</span><span class="va">duration</span>,</span>
<span>  event <span class="op">=</span> <span class="va">train</span><span class="op">$</span><span class="va">event</span>,</span>
<span>  X <span class="op">=</span> <span class="va">X_tr</span>,</span>
<span>  newX <span class="op">=</span> <span class="va">X_te</span>,</span>
<span>  new.times <span class="op">=</span> <span class="va">new.times</span>,</span>
<span>  event.SL.library <span class="op">=</span> <span class="va">my_screen_library</span>, <span class="co"># Pass our screened library</span></span>
<span>  cens.SL.library <span class="op">=</span> <span class="va">cens_library</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>saveFitLibrary <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">T</span>,</span>
<span>  nFolds <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="evaluating-the-screened-ensemble">4. Evaluating the Screened Ensemble<a class="anchor" aria-label="anchor" href="#evaluating-the-screened-ensemble"></a>
</h2>
<p>Despite injecting 100 columns of pure noise, our ensemble still
performs exceptionally well because the screening algorithms
successfully filtered out the irrelevant variables before the base
learners could overfit to them.</p>
<p>We can evaluate this exactly as we did in previous tutorials using
<code><a href="../reference/eval_summary.html">eval_summary()</a></code> and <code><a href="../reference/plot_benchmark.html">plot_benchmark()</a></code>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Check the integrated performance</span></span>
<span><span class="va">screened_performance</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/eval_summary.html">eval_summary</a></span><span class="op">(</span></span>
<span>  object <span class="op">=</span> <span class="va">fit_highdim</span>,</span>
<span>  newdata <span class="op">=</span> <span class="va">X_te</span>,</span>
<span>  time <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">duration</span>,</span>
<span>  event <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">event</span>,</span>
<span>  eval_times <span class="op">=</span> <span class="va">new.times</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Generating predictions on test data...</span></span>
<span><span class="co">#&gt; Evaluating SuperSurv Ensemble...</span></span>
<span><span class="co">#&gt; Evaluating Base Learner 1/4: surv.coxph_screen.all...</span></span>
<span><span class="co">#&gt; Evaluating Base Learner 2/4: surv.coxph_screen.marg...</span></span>
<span><span class="co">#&gt; Evaluating Base Learner 3/4: surv.weibull_screen.elasticnet...</span></span>
<span><span class="co">#&gt; Evaluating Base Learner 4/4: surv.rpart_screen.var...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ========================================================</span></span>
<span><span class="co">#&gt;              SuperSurv Evaluation Benchmark             </span></span>
<span><span class="co">#&gt; ========================================================</span></span>
<span><span class="co">#&gt;                           Model    IBS  Uno_C   iAUC</span></span>
<span><span class="co">#&gt;              SuperSurv_Ensemble 0.2014 0.6373 0.6779</span></span>
<span><span class="co">#&gt;           surv.coxph_screen.all 0.2009 0.6350 0.6794</span></span>
<span><span class="co">#&gt;          surv.coxph_screen.marg 0.2004 0.6270 0.6775</span></span>
<span><span class="co">#&gt;  surv.weibull_screen.elasticnet 0.2005 0.6324 0.6798</span></span>
<span><span class="co">#&gt;           surv.rpart_screen.var 0.2106 0.6104 0.6349</span></span>
<span><span class="co">#&gt; ========================================================</span></span>
<span><span class="co">#&gt; * IBS &amp; iAUC integrated over: [50.00, 200.00]</span></span>
<span><span class="co">#&gt; * Uno's C-index evaluated using risk at time: 125.00</span></span>
<span><span class="co">#&gt; Note: Lower IBS is better. Higher Uno_C and iAUC are better.</span></span>
<span></span>
<span><span class="co"># Plot the benchmark</span></span>
<span><span class="co"># plot_benchmark(fit_highdim, newdata = X_te, time = test$duration, event = test$event, eval_times = new.times)</span></span></code></pre></div>
<p>By leveraging <code>SuperSurv</code>’s screening capabilities, you
can scale your survival analysis to massive genomic and clinical
datasets without sacrificing computational speed or predictive
accuracy.</p>
</div>
<div class="section level2">
<h2 id="identifying-the-selected-features">5. Identifying the Selected Features<a class="anchor" aria-label="anchor" href="#identifying-the-selected-features"></a>
</h2>
<p>After the Super Learner finishes its cross-validation and fitting,
you likely want to know <em>which</em> variables actually survived the
screening process. In clinical and biological research, these selected
features often represent the most important biomarkers or predictive
genes.</p>
<p><code>SuperSurv</code> stores this screening information directly
inside the fitted model object, specifically separated into
<code>event.whichScreen</code> and <code>cens.whichScreen</code>. We can
extract the logical matrix that indicates which columns were passed to
each specific base learner.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># The event.whichScreen object is a logical matrix.</span></span>
<span><span class="co"># Rows correspond to the predictors, and columns correspond to the algorithms in our event library.</span></span>
<span></span>
<span><span class="co"># 1. Get the logical vector for the 2nd model (Row 2)</span></span>
<span><span class="va">is_selected</span> <span class="op">&lt;-</span> <span class="va">fit_highdim</span><span class="op">$</span><span class="va">event.whichScreen</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span> </span>
<span></span>
<span><span class="co"># 2. Map it to our original column names</span></span>
<span><span class="va">selected_features</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">X_tr</span><span class="op">)</span><span class="op">[</span><span class="va">is_selected</span><span class="op">]</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Total features evaluated:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">X_tr</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Total features evaluated: 29</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Features retained by Elastic Net:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">selected_features</span><span class="op">)</span>, <span class="st">"\n\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Features retained by Elastic Net: 10</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Selected Features:\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Selected Features:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">selected_features</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1] "x0"       "x1"       "x2"       "x3"       "x4"       "x5"      </span></span>
<span><span class="co">#&gt;  [7] "x6"       "x7"       "x8"       "noise_10"</span></span></code></pre></div>
<p>By extracting these features, you can seamlessly transition from pure
predictive modeling into downstream biological inference or pathway
analysis.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://scholar.google.com/citations?hl=en&amp;user=PFjMl6sAAAAJ" class="external-link">Yue Lyu</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>

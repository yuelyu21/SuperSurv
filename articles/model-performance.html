<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>2. Model Performance &amp; Benchmarking • SuperSurv</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="2. Model Performance &amp; Benchmarking">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">SuperSurv</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/supersurv-ensemble.html">Get Started</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-tutorials" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Tutorials</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-tutorials">
<li><a class="dropdown-item" href="../articles/supersurv-ensemble.html">1. The SuperSurv Ensemble</a></li>
    <li><a class="dropdown-item" href="../articles/supersurv-best.html">2. Selection vs. Ensemble</a></li>
    <li><a class="dropdown-item" href="../articles/model-performance.html">3. Model Performance</a></li>
    <li><a class="dropdown-item" href="../articles/screening-methods.html">4. Screening Methods</a></li>
    <li><a class="dropdown-item" href="../articles/base-learner-rfsrc.html">5. Random Forests (rfsrc)</a></li>
    <li><a class="dropdown-item" href="../articles/parametric-models.html">6. Parametric Models</a></li>
    <li><a class="dropdown-item" href="../articles/shap-explanations.html">7. SHAP Interpretability</a></li>
    <li><a class="dropdown-item" href="../articles/scaleup-parallel.html">8. Parallel Processing</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/yuelyu21/SuperSurv" aria-label="GitHub"><span class="fa fa-github"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>2. Model Performance &amp; Benchmarking</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/yuelyu21/SuperSurv/blob/master/vignettes/model-performance.Rmd" class="external-link"><code>vignettes/model-performance.Rmd</code></a></small>
      <div class="d-none name"><code>model-performance.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Once a <code>SuperSurv</code> ensemble is trained, we must rigorously
prove that it outperforms the individual base learners. Because survival
data involves right-censoring, we cannot use standard classification
metrics like simple accuracy.</p>
<p>Instead, we evaluate the model across three critical dimensions: 1.
<strong>Calibration:</strong> Does the predicted survival probability
match the actual observed survival rate? 2. <strong>Discrimination (AUC
&amp; C-index):</strong> Can the model correctly rank which patient will
survive longer? 3. <strong>Overall Accuracy (Brier Score):</strong> A
combined measure of both calibration and discrimination.</p>
<p>This tutorial demonstrates how to extract these metrics and visualize
the benchmark comparisons using <code>SuperSurv</code>’s built-in
evaluation suite.</p>
</div>
<div class="section level2">
<h2 id="data-preparation-the-extrapolation-rule">1. Data Preparation &amp; The Extrapolation Rule<a class="anchor" aria-label="anchor" href="#data-preparation-the-extrapolation-rule"></a>
</h2>
<p>We begin by loading the <code>metabric</code> dataset and defining
our evaluation time grid (<code>new.times</code>).</p>
<p><strong>Crucial Methodological Note:</strong> Your
<code>new.times</code> grid should <em>never</em> exceed the maximum
observed follow-up time in your training cohort. For example, if your
training data only spans 1 to 100 days, predicting survival at day 150
is extrapolation. Non-parametric models (like Survival Trees)
mathematically cannot extrapolate, and parametric models (like Weibulls)
will generate highly unreliable tail estimates. Always bind your
evaluation grid within the limits of your observed data!</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/yuelyu21/SuperSurv" class="external-link">SuperSurv</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/therneau/survival" class="external-link">survival</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"metabric"</span>, package <span class="op">=</span> <span class="st">"SuperSurv"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">train_idx</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">metabric</span><span class="op">)</span>, <span class="fl">0.7</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">metabric</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">metabric</span><span class="op">[</span><span class="va">train_idx</span>, <span class="op">]</span></span>
<span><span class="va">test</span>  <span class="op">&lt;-</span> <span class="va">metabric</span><span class="op">[</span><span class="op">-</span><span class="va">train_idx</span>, <span class="op">]</span></span>
<span></span>
<span><span class="va">X_tr</span> <span class="op">&lt;-</span> <span class="va">train</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">grep</a></span><span class="op">(</span><span class="st">"^x"</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">metabric</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">X_te</span> <span class="op">&lt;-</span> <span class="va">test</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/grep.html" class="external-link">grep</a></span><span class="op">(</span><span class="st">"^x"</span>, <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">metabric</span><span class="op">)</span><span class="op">)</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Our max follow-up is well beyond 200, so this grid is safe.</span></span>
<span><span class="va">new.times</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">200</span>, by <span class="op">=</span> <span class="fl">25</span><span class="op">)</span> </span></code></pre></div>
</div>
<div class="section level2">
<h2 id="train-the-benchmark-ensemble">2. Train the Benchmark Ensemble<a class="anchor" aria-label="anchor" href="#train-the-benchmark-ensemble"></a>
</h2>
<p>We will fit an ensemble consisting of a Cox model, a Weibull model,
and a Survival Tree using the default Least Squares meta-learner.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">my_library</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"surv.coxph"</span>, <span class="st">"surv.weibull"</span>, <span class="st">"surv.rpart"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">fit_supersurv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/SuperSurv.html">SuperSurv</a></span><span class="op">(</span></span>
<span>  time <span class="op">=</span> <span class="va">train</span><span class="op">$</span><span class="va">duration</span>,</span>
<span>  event <span class="op">=</span> <span class="va">train</span><span class="op">$</span><span class="va">event</span>,</span>
<span>  X <span class="op">=</span> <span class="va">X_tr</span>,</span>
<span>  newX <span class="op">=</span> <span class="va">X_te</span>,</span>
<span>  new.times <span class="op">=</span> <span class="va">new.times</span>,</span>
<span>  event.SL.library <span class="op">=</span> <span class="va">my_library</span>,</span>
<span>  cens.SL.library <span class="op">=</span> <span class="va">my_library</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>saveFitLibrary <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  nFolds <span class="op">=</span> <span class="fl">3</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="extracting-integrated-metrics">3. Extracting Integrated Metrics<a class="anchor" aria-label="anchor" href="#extracting-integrated-metrics"></a>
</h2>
<p>The <code><a href="../reference/eval_summary.html">eval_summary()</a></code> function automatically generates
predictions on your test set and returns a clean, comparative table of
the <em>integrated</em> metrics across your entire time grid.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Evaluate performance directly using the fitted model and test data</span></span>
<span><span class="va">performance_results</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/eval_summary.html">eval_summary</a></span><span class="op">(</span></span>
<span>  object <span class="op">=</span> <span class="va">fit_supersurv</span>,</span>
<span>  newdata <span class="op">=</span> <span class="va">X_te</span>,</span>
<span>  time <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">duration</span>,</span>
<span>  event <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">event</span>,</span>
<span>  eval_times <span class="op">=</span> <span class="va">new.times</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Generating predictions on test data...</span></span>
<span><span class="co">#&gt; Evaluating SuperSurv Ensemble...</span></span>
<span><span class="co">#&gt; Evaluating Base Learner 1/3: surv.coxph_screen.all...</span></span>
<span><span class="co">#&gt; Evaluating Base Learner 2/3: surv.weibull_screen.all...</span></span>
<span><span class="co">#&gt; Evaluating Base Learner 3/3: surv.rpart_screen.all...</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ========================================================</span></span>
<span><span class="co">#&gt;              SuperSurv Evaluation Benchmark             </span></span>
<span><span class="co">#&gt; ========================================================</span></span>
<span><span class="co">#&gt;                    Model    IBS  Uno_C   iAUC</span></span>
<span><span class="co">#&gt;       SuperSurv_Ensemble 0.2056 0.6317 0.6645</span></span>
<span><span class="co">#&gt;    surv.coxph_screen.all 0.2071 0.6291 0.6619</span></span>
<span><span class="co">#&gt;  surv.weibull_screen.all 0.2068 0.6289 0.6615</span></span>
<span><span class="co">#&gt;    surv.rpart_screen.all 0.2156 0.5931 0.6266</span></span>
<span><span class="co">#&gt; ========================================================</span></span>
<span><span class="co">#&gt; * IBS &amp; iAUC integrated over: [50.00, 200.00]</span></span>
<span><span class="co">#&gt; * Uno's C-index evaluated using risk at time: 125.00</span></span>
<span><span class="co">#&gt; Note: Lower IBS is better. Higher Uno_C and iAUC are better.</span></span></code></pre></div>
<p><em>Note: Look for the model with the lowest IBS (Integrated Brier
Score) and the highest iAUC/Uno’s C-index.</em></p>
</div>
<div class="section level2">
<h2 id="visualizing-longitudinal-benchmarks">4. Visualizing Longitudinal Benchmarks<a class="anchor" aria-label="anchor" href="#visualizing-longitudinal-benchmarks"></a>
</h2>
<p>A single integrated number rarely tells the whole story. Different
models excel at different follow-up periods (e.g., a Cox model might
dominate short-term survival, while a Random Forest dominates
long-term).</p>
<p>The <code><a href="../reference/plot_benchmark.html">plot_benchmark()</a></code> function generates a stacked
dashboard to visualize this dynamic performance over time.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_benchmark.html">plot_benchmark</a></span><span class="op">(</span></span>
<span>  object <span class="op">=</span> <span class="va">fit_supersurv</span>,</span>
<span>  newdata <span class="op">=</span> <span class="va">X_te</span>,</span>
<span>  time <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">duration</span>,</span>
<span>  event <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">event</span>,</span>
<span>  eval_times <span class="op">=</span> <span class="va">new.times</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Generating predictions for benchmark plots...</span></span>
<span><span class="co">#&gt; Calculating time-dependent metrics...</span></span></code></pre></div>
<p><img src="model-performance_files/figure-html/plot-benchmark-1.png" class="r-plt" alt="" width="672" style="display: block; margin: auto;"></p>
<div class="section level3">
<h3 id="interpreting-the-curves">Interpreting the Curves:<a class="anchor" aria-label="anchor" href="#interpreting-the-curves"></a>
</h3>
<ul>
<li>
<strong>IPCW Brier Score Plot:</strong> Look for the curve that
stays the <em>lowest</em>. The <code>SuperSurv</code> ensemble should
ideally hug the bottom edge.</li>
<li>
<strong>Time-Dependent AUC Plot:</strong> Look for the curve that
stays the <em>highest</em> (closest to 1.0).</li>
<li>
<strong>Uno’s C-index Plot:</strong> Evaluates the global C-index
using the specific predictions generated at each time point. Look for
the curve that stays the <em>highest</em>.</li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="assessing-clinical-calibration">5. Assessing Clinical Calibration<a class="anchor" aria-label="anchor" href="#assessing-clinical-calibration"></a>
</h2>
<p>Before deploying a model to the clinic, doctors need to know if the
probabilities are reliable. If the model predicts a patient has a 40%
chance of surviving past Time = 100, do exactly 40% of similar patients
actually survive?</p>
<p>We use <code><a href="../reference/plot_calibration.html">plot_calibration()</a></code> to evaluate this at a specific
clinical milestone. The function groups patients into risk quantiles and
plots their predicted probability against the actual observed
Kaplan-Meier survival rate.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Assess calibration specifically at Time = 150</span></span>
<span><span class="fu"><a href="../reference/plot_calibration.html">plot_calibration</a></span><span class="op">(</span></span>
<span>  object <span class="op">=</span> <span class="va">fit_supersurv</span>,</span>
<span>  newdata <span class="op">=</span> <span class="va">X_te</span>,</span>
<span>  time <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">duration</span>,</span>
<span>  event <span class="op">=</span> <span class="va">test</span><span class="op">$</span><span class="va">event</span>,</span>
<span>  eval_time <span class="op">=</span> <span class="fl">150</span>,</span>
<span>  bins <span class="op">=</span> <span class="fl">5</span> <span class="co"># Group patients into 5 risk quintiles</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><img src="model-performance_files/figure-html/plot-calibration-1.png" class="r-plt" alt="" width="672" style="display: block; margin: auto;"></p>
<p><strong>Interpretation:</strong> A perfectly calibrated model will
follow the 45-degree dashed black line. Points above the line indicate
the model is <em>under-predicting</em> survival (being too pessimistic),
while points below the line indicate it is <em>over-predicting</em>
survival (being too optimistic).</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://scholar.google.com/citations?hl=en&amp;user=PFjMl6sAAAAJ" class="external-link">Yue Lyu</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluation.R
\name{eval_summary}
\alias{eval_summary}
\title{Evaluate SuperSurv Predictions on Test Data}
\usage{
eval_summary(
  object,
  newdata,
  time,
  event,
  eval_times,
  risk_time = median(eval_times)
)
}
\arguments{
\item{object}{A fitted \code{SuperSurv} object.}

\item{newdata}{A data.frame of test covariates.}

\item{time}{Numeric vector of observed follow-up times for the test set.}

\item{event}{Numeric vector of event indicators for the test set.}

\item{eval_times}{Numeric vector of times at which to evaluate survival predictions.}

\item{risk_time}{Numeric. The specific time horizon to use when extracting risk
scores for Uno's C-index. Defaults to the median of \code{eval_times}.}
}
\value{
A data.frame containing the benchmark metrics for all models.
}
\description{
Computes the Integrated Brier Score (IBS), Uno's C-index, and Integrated AUC (iAUC)
for the SuperSurv ensemble and all individual base learners.
}
